# document-processor/app/core/rabbitmq_consumer.py
"""
üîÑ –£–ª—É—á—à–µ–Ω–Ω—ã–π RabbitMQ Consumer
- –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–æ–∫ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ Celery –∑–∞–¥–∞—á
- –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç—É—Å–∞ –≤ Redis –ø—Ä–∏ –æ—à–∏–±–∫–∞—Ö
- Retry –º–µ—Ö–∞–Ω–∏–∑–º –¥–ª—è failed messages
- Dead Letter Queue –æ–±—Ä–∞–±–æ—Ç–∫–∞
"""

import aio_pika
import json
import asyncio
import logging
from typing import Optional
import redis.asyncio as aioredis
from datetime import datetime

from ..tasks.processing import celery_app
from .config import settings

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)

logger = logging.getLogger(__name__)


class RedisStatusUpdater:
    """Helper –∫–ª–∞—Å—Å –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è —Å—Ç–∞—Ç—É—Å–æ–≤ –≤ Redis –∏–∑ consumer"""
    
    def __init__(self):
        self.redis = None
    
    async def connect(self):
        """–ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ Redis"""
        try:
            self.redis = await aioredis.from_url(
                settings.REDIS_URL,
                encoding="utf-8",
                decode_responses=True
            )
            await self.redis.ping()
            logger.info("‚úÖ Redis connection established in consumer")
        except Exception as e:
            logger.error(f"‚ùå Failed to connect to Redis: {e}")
            raise
    
    async def update_task_failed(self, task_id: str, error_message: str):
        """–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç—É—Å–∞ –∑–∞–¥–∞—á–∏ –Ω–∞ failed"""
        try:
            if not self.redis:
                await self.connect()
            
            key = f"task:{task_id}:status"
            current_data = await self.redis.get(key)
            
            if current_data:
                task_data = json.loads(current_data)
                task_data.update({
                    "status": "failed",
                    "progress": 100,
                    "message": "–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –∑–∞–¥–∞—á–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏",
                    "error": {
                        "type": "consumer_error",
                        "message": error_message
                    },
                    "failed_at": datetime.now().isoformat()
                })
                
                await self.redis.setex(key, 3600, json.dumps(task_data))
                logger.info(f"üìù Updated task {task_id} to failed in Redis")
            else:
                logger.warning(f"‚ö†Ô∏è Task {task_id} not found in Redis")
                
        except Exception as e:
            logger.error(f"‚ùå Failed to update Redis for task {task_id}: {e}")
    
    async def close(self):
        """–ó–∞–∫—Ä—ã—Ç–∏–µ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è"""
        if self.redis:
            await self.redis.close()


# –ì–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä Redis updater
redis_updater = RedisStatusUpdater()


async def on_message(message: aio_pika.IncomingMessage):
    """
    üîÑ –û–±—Ä–∞–±–æ—Ç–∫–∞ –≤—Ö–æ–¥—è—â–µ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è –∏–∑ RabbitMQ
    
    –û—Å–Ω–æ–≤–Ω—ã–µ —É–ª—É—á—à–µ–Ω–∏—è:
    - Try-catch –æ–±—ë—Ä—Ç–∫–∞ –¥–ª—è –≤—Å–µ–π –ª–æ–≥–∏–∫–∏
    - –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ Redis –ø—Ä–∏ –æ—à–∏–±–∫–∞—Ö
    - –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –≤—Å–µ—Ö —ç—Ç–∞–ø–æ–≤
    """
    async with message.process():
        task_id = None
        
        try:
            # 1. –ü–∞—Ä—Å–∏–Ω–≥ —Å–æ–æ–±—â–µ–Ω–∏—è
            try:
                payload = json.loads(message.body)
                logger.info(f"üì• Received message: {payload}")
            except json.JSONDecodeError as e:
                logger.error(f"‚ùå Invalid JSON in message: {e}")
                return  # Acknowledge –Ω–æ –Ω–µ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º
            
            # 2. –í–∞–ª–∏–¥–∞—Ü–∏—è payload
            task_id = payload.get("task_id")
            if not task_id:
                logger.error("‚ùå Missing task_id in payload")
                return
            
            task_type = payload.get("type", "single_file")
            
            # 3. –û–±—Ä–∞–±–æ—Ç–∫–∞ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ç–∏–ø–∞
            if task_type == "single_file":
                await process_single_file(payload, task_id)
                
            elif task_type == "folder":
                await process_folder(payload, task_id)
                
            else:
                logger.error(f"‚ùå Unknown task type: {task_type}")
                await redis_updater.update_task_failed(
                    task_id,
                    f"Unknown task type: {task_type}"
                )
                
        except Exception as e:
            logger.error(f"‚ùå Critical error processing message: {e}", exc_info=True)
            
            # –û–±–Ω–æ–≤–ª—è–µ–º Redis –µ—Å–ª–∏ –µ—Å—Ç—å task_id
            if task_id:
                await redis_updater.update_task_failed(
                    task_id,
                    f"Consumer error: {str(e)}"
                )


async def process_single_file(payload: dict, task_id: str):
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ –æ–¥–∏–Ω–æ—á–Ω–æ–≥–æ —Ñ–∞–π–ª–∞"""
    try:
        file_path = payload.get("file_path")
        filename = payload.get("filename")
        
        if not file_path or not filename:
            raise ValueError("Missing file_path or filename in payload")
        
        logger.info(f"üì§ Sending to Celery: {task_id} - {filename}")
        
        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –≤ Celery
        celery_task = celery_app.send_task(
            "worker-document-processor.generate_embedding",
            args=[file_path],
            kwargs={
                "onlyfile": False,
                "api_task_id": task_id
            },
            task_id=task_id,
            queue="documents.tasks"
        )
        
        logger.info(f"‚úÖ Celery task created: {celery_task.id}")
        
    except Exception as e:
        logger.error(f"‚ùå Error processing single file: {e}")
        await redis_updater.update_task_failed(
            task_id,
            f"Failed to create Celery task: {str(e)}"
        )
        raise


async def process_folder(payload: dict, task_id: str):
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ –ø–∞–ø–∫–∏ —Å —Ñ–∞–π–ª–∞–º–∏"""
    try:
        file_paths = payload.get("file_paths")
        folder_name = payload.get("folder_name", "unknown")
        
        if not file_paths:
            raise ValueError("Missing file_paths in payload")
        
        logger.info(f"üì§ Sending batch to Celery: {task_id} - {folder_name} ({len(file_paths)} files)")
        
        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –≤ Celery
        celery_task = celery_app.send_task(
            "worker-document-processor.generate_embedding_batch",
            args=[file_paths],
            kwargs={
                "folder_name": folder_name,
                "api_task_id": task_id
            },
            task_id=task_id,
            queue="documents.tasks"
        )
        
        logger.info(f"‚úÖ Celery batch task created: {celery_task.id}")
        
    except Exception as e:
        logger.error(f"‚ùå Error processing folder: {e}")
        await redis_updater.update_task_failed(
            task_id,
            f"Failed to create batch Celery task: {str(e)}"
        )
        raise


async def setup_dead_letter_queue(channel):
    """
    –ù–∞—Å—Ç—Ä–æ–π–∫–∞ Dead Letter Queue –¥–ª—è failed messages
    
    –°–æ–æ–±—â–µ–Ω–∏—è –ø–æ–ø–∞–¥–∞—é—Ç —Å—é–¥–∞ –µ—Å–ª–∏:
    - –ü—Ä–µ–≤—ã—à–µ–Ω TTL (60 —Å–µ–∫—É–Ω–¥)
    - Message rejected —Å requeue=False
    """
    try:
        # Dead Letter Exchange
        dlx = await channel.declare_exchange(
            'dlx',
            aio_pika.ExchangeType.TOPIC,
            durable=True
        )
        
        # Dead Letter Queue
        dlq = await channel.declare_queue(
            'dlq.document_processor',
            durable=True,
            arguments={
                'x-message-ttl': 86400000,  # 24 —á–∞—Å–∞
            }
        )
        
        await dlq.bind(dlx, routing_key='dlq.document_processor')
        
        logger.info("‚úÖ Dead Letter Queue configured")
        
    except Exception as e:
        logger.error(f"‚ùå Failed to setup DLQ: {e}")
        raise


async def main():
    """
    üöÄ –ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è consumer
    
    –ù–∞—Å—Ç—Ä–æ–π–∫–∞:
    - RabbitMQ connection —Å robust reconnect
    - QoS –¥–ª—è –Ω–∞–¥—ë–∂–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏
    - Exchange –∏ Queue –æ–±—ä—è–≤–ª–µ–Ω–∏–µ
    - Dead Letter Queue
    - Redis connection –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è —Å—Ç–∞—Ç—É—Å–æ–≤
    """
    try:
        # –ü–æ–¥–∫–ª—é—á–∞–µ–º—Å—è –∫ Redis
        await redis_updater.connect()
        
        # –ü–æ–¥–∫–ª—é—á–∞–µ–º—Å—è –∫ RabbitMQ
        connection = await aio_pika.connect_robust(
            settings.RABBITMQ_URL,
            timeout=30
        )

        channel = await connection.channel()
        
        # –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º QoS
        await channel.set_qos(prefetch_count=1)

        # Exchange –¥–ª—è –≤—Ö–æ–¥—è—â–∏—Ö —Å–æ–æ–±—â–µ–Ω–∏–π
        exchange = await channel.declare_exchange(
            "documents.events",
            aio_pika.ExchangeType.TOPIC,
            durable=True
        )

        # –û—Å–Ω–æ–≤–Ω–∞—è –æ—á–µ—Ä–µ–¥—å
        queue = await channel.declare_queue(
            "document_processor_queue",
            durable=True,
            arguments={
                'x-message-ttl': 60000,  # 60 —Å–µ–∫—É–Ω–¥
                'x-dead-letter-exchange': 'dlx',
                'x-dead-letter-routing-key': 'dlq.document_processor'
            }
        )

        # –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º Dead Letter Queue
        await setup_dead_letter_queue(channel)

        # –ë–∏–Ω–¥–∏–º –æ—á–µ—Ä–µ–¥—å –∫ exchange
        await queue.bind(exchange, routing_key="file.process")
        await queue.bind(exchange, routing_key="folder.process")

        logger.info("="*60)
        logger.info("üî• RabbitMQ Consumer Started")
        logger.info("="*60)
        logger.info(f"üì• Listening on queue: document_processor_queue")
        logger.info(f"üîå Binding keys: file.process, folder.process")
        logger.info(f"üìä QoS prefetch: 1")
        logger.info("="*60)

        # –ù–∞—á–∏–Ω–∞–µ–º —Å–ª—É—à–∞—Ç—å —Å–æ–æ–±—â–µ–Ω–∏—è
        await queue.consume(on_message)

        # Keep consumer running
        await asyncio.Future()
        
    except KeyboardInterrupt:
        logger.info("üõë Consumer stopped by user")
        
    except Exception as e:
        logger.error(f"‚ùå Consumer error: {e}", exc_info=True)
        raise
        
    finally:
        # –ó–∞–∫—Ä—ã–≤–∞–µ–º Redis
        await redis_updater.close()


if __name__ == "__main__":
    asyncio.run(main())