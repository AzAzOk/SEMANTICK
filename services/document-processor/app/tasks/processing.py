import shutil
from celery import Celery
from pathlib import Path
from ..core.chanking.text_spliter import TextSplitter
from ..core.parsers_system import ParserManager
from ..core.config import settings
import json
import logging
import redis.asyncio as aioredis
import asyncio
from datetime import datetime

logger = logging.getLogger(__name__)

# –°–æ–∑–¥–∞–µ–º Celery app —Å —è–≤–Ω—ã–º –∏–º–µ–Ω–µ–º
celery_app = Celery(
    'app.tasks.processing',  # –Ø–≤–Ω–æ–µ –∏–º—è –¥–ª—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–π —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏–∏
    broker=settings.RABBITMQ_URL,
    backend=settings.REDIS_URL
)

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ Celery
celery_app.conf.update(
    # –ë–∞–∑–æ–≤–∞—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
    result_expires=settings.RESULT_EXP,
    task_track_started=settings.T_TRACK_STR,
    task_soft_time_limit=settings.T_SOFT_TIME_LIMIT,
    task_time_limit=settings.T_TIME_LIM,
    task_acks_late=settings.T_ACKS_LATE,
    worker_prefetch_multiplier=settings.W_PREFETCH_MULT,
    task_reject_on_worker_lost=settings.T_REJECT_ON_W_LOST,
    worker_max_tasks_per_child=settings.W_MAX_T_PER_CHILD,
    
    # –ò–º—è –∑–∞–¥–∞—á–∏ –¥–æ–ª–∂–Ω–æ —Å–æ–≤–ø–∞–¥–∞—Ç—å
    task_default_queue='documents.tasks',
    
    # –ò–º–ø–æ—Ä—Ç –∑–∞–¥–∞—á
    imports=['app.tasks.processing'],
    
    # –ò–º–µ–Ω–∞ –∑–∞–¥–∞—á
    task_routes={
        'app.tasks.processing.generate_embedding': {
            'queue': 'documents.tasks'
        },
        'app.tasks.processing.generate_embedding_batch': {
            'queue': 'documents.tasks'
        }
    },
    
    broker_transport_options={
        'visibility_timeout': settings.BTO_VT,
        'socket_keepalive': settings.BTO_SK,
        'socket_keepalive_options': {
            1: 1,
            2: 1,
            3: 5,
        },
    },
)

# –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å Redis
async def update_task_status_async(task_id: str, **updates):
    """–ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç—É—Å–∞ –∑–∞–¥–∞—á–∏ –≤ Redis"""
    try:
        redis_client = aioredis.from_url(
            settings.REDIS_URL,
            encoding="utf-8",
            decode_responses=True
        )
        
        key = f"task:{task_id}:status"
        current_data = await redis_client.get(key)
        
        if current_data:
            task_data = json.loads(current_data)
            task_data.update(updates)
            task_data['last_updated'] = datetime.now().isoformat()
            
            await redis_client.setex(key, 3600, json.dumps(task_data))
            logger.info(f"üìù Updated Redis task status: {task_id} - {updates.get('status', 'no status')}")
        else:
            logger.warning(f"‚ö†Ô∏è Task {task_id} not found in Redis")
        
        await redis_client.close()
        return True
        
    except Exception as e:
        logger.error(f"‚ùå Failed to update Redis task status {task_id}: {e}")
        return False

def update_task_status_sync(task_id: str, **updates):
    """–°–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –æ–±—ë—Ä—Ç–∫–∞ –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è —Å—Ç–∞—Ç—É—Å–∞ –≤ Redis"""
    try:
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        result = loop.run_until_complete(update_task_status_async(task_id, **updates))
        loop.close()
        return result
    except Exception as e:
        logger.error(f"‚ùå Sync wrapper error: {e}")
        return False

def _cleanup_file(filename: str, worker_name: str = "") -> None:
    """–£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è —Ñ–∞–π–ª–∞ —Å –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ–º"""
    try:
        if filename.startswith("uploads") or filename.startswith("uploads\\"):
            file_path = Path(filename)
        else:
            UPLOADS = Path(settings.UPLOAD_DIR)
            file_path = UPLOADS / filename
        
        if file_path.exists():
            file_path.unlink()
            logger.info(f"[{worker_name}] –§–∞–π–ª —É–¥–∞–ª—ë–Ω: {file_path}")
            return True
        else:
            logger.warning(f"[{worker_name}] –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è: {file_path}")
            return False
    except Exception as e:
        logger.error(f"[{worker_name}] –û—à–∏–±–∫–∞ —É–¥–∞–ª–µ–Ω–∏—è —Ñ–∞–π–ª–∞ {filename}: {e}")
        return False

@celery_app.task(bind=True, name='worker-document-processor.generate_embedding')
def generate_embedding(self, filename: str, onlyfile: bool = False, api_task_id: str = None):
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–∞–π–ª–∞ —Å –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å–∞ –∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ–º —Å—Ç–∞—Ç—É—Å–∞ –≤ Redis"""
    
    worker_name = self.request.hostname
    filenames = Path(filename)
    task_id = api_task_id or self.request.id
    
    logger.info(f"üöÄ [{worker_name}] Starting task {task_id} for file: {filename}")
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º display –∏–º—è —Ñ–∞–π–ª–∞
    dispach = filename
    if onlyfile:
        parts = filename.split('\\')
        dispach = '\\'.join(parts[2:]) if len(parts) > 2 else filename
    
    # 1. –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç—É—Å: –Ω–∞—á–∞—Ç–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∞
    if task_id and not task_id.startswith('celery-'):
        update_task_status_sync(
            task_id,
            status="processing",
            progress=0,
            current_step=1,
            total_steps=6,
            message="–ù–∞—á–∏–Ω–∞–µ—Ç—Å—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–∞–π–ª–∞...",
            filename=dispach or filenames.name,
            worker=worker_name,
            started_at=datetime.now().isoformat()
        )
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ñ–æ—Ä–º–∞—Ç —Ñ–∞–π–ª–∞
    ext = filenames.suffix.lower()
    if ext not in settings.SUPPORTED_EXTENSIONS:
        _cleanup_file(filename, worker_name)
        
        if task_id and not task_id.startswith('celery-'):
            update_task_status_sync(
                task_id,
                status="failed",
                progress=100,
                current_step=1,
                total_steps=6,
                message=f"–ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç —Ñ–∞–π–ª–∞: {ext}",
                error={
                    "type": "unsupported_format",
                    "message": f"–§–æ—Ä–º–∞—Ç {ext} –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è"
                },
                completed_at=datetime.now().isoformat()
            )
        
        return {
            "status": "skipped",
            "reason": "unsupported_format",
            "file_name": filename,
            "message": f"–§–∞–π–ª {filename} –ø—Ä–æ–ø—É—â–µ–Ω (–Ω–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç {ext})",
            "worker": worker_name
        }

    try:
        # 2. –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ñ–∞–π–ª–∞ –Ω–∞ –¥—É–±–ª–∏–∫–∞—Ç—ã (—à–∞–≥ 1)
        logger.info(f"[{worker_name}] –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ñ–∞–π–ª–∞ {dispach or filename}")
        
        if task_id and not task_id.startswith('celery-'):
            update_task_status_sync(
                task_id,
                current_step=2,
                progress=15,
                status="processing",
                message="–ü—Ä–æ–≤–µ—Ä–∫–∞ —Ñ–∞–π–ª–∞ –Ω–∞ –¥—É–±–ª–∏–∫–∞—Ç—ã..."
            )
        
        # TODO: –î–æ–±–∞–≤–∏—Ç—å –ø—Ä–æ–≤–µ—Ä–∫—É –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ –∏–∑ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
        # if reserch_file_name(dispach or filename):
        #     _cleanup_file(filename, worker_name)
        #     update_task_status_sync(task_id, status="skipped", reason="already_exists")
        #     return {"status": "skipped", "reason": "already_exists"}

        # 3. –ü–æ–∏—Å–∫ —Ñ–∞–π–ª–∞ –≤ —Ñ–∞–π–ª–æ–≤–æ–π —Å–∏—Å—Ç–µ–º–µ (—à–∞–≥ 2)
        if task_id and not task_id.startswith('celery-'):
            update_task_status_sync(
                task_id,
                current_step=3,
                progress=30,
                status="processing", 
                message="–ü–æ–∏—Å–∫ —Ñ–∞–π–ª–∞ –≤ —Ñ–∞–π–ª–æ–≤–æ–π —Å–∏—Å—Ç–µ–º–µ..."
            )
        
        if filename.startswith("uploads") or filename.startswith("uploads\\"):
            file_path = Path(filename)
        else:
            UPLOADS = Path(settings.UPLOAD_DIR)
            file_path = UPLOADS / filename
        
        if not file_path.exists():
            raise FileNotFoundError(f"–§–∞–π–ª {filename} –Ω–µ –Ω–∞–π–¥–µ–Ω –ø–æ –ø—É—Ç–∏: {file_path}")
        
        logger.info(f"[{worker_name}] –§–∞–π–ª –Ω–∞–π–¥–µ–Ω: {file_path.resolve()}")
        
        # 4. –ü–∞—Ä—Å–∏–Ω–≥ —Ñ–∞–π–ª–∞ (—à–∞–≥ 3)
        if task_id and not task_id.startswith('celery-'):
            update_task_status_sync(
                task_id,
                current_step=4,
                progress=45,
                status="processing",
                message="–ü–∞—Ä—Å–∏–Ω–≥ —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ —Ñ–∞–π–ª–∞..."
            )
        
        manager = ParserManager()
        splitter = TextSplitter()
        
        ext = manager._parser_extension(str(file_path))
        logger.info(f"[{worker_name}] –†–∞—Å—à–∏—Ä–µ–Ω–∏–µ —Ñ–∞–π–ª–∞: {ext}")
        
        parser_class = manager._find_parser_in_registry(ext)
        if parser_class is None:
            raise ValueError(f"–ü–∞—Ä—Å–µ—Ä –¥–ª—è —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è .{ext} –Ω–µ –Ω–∞–π–¥–µ–Ω")
        
        result_parser = manager._ransfer_selected_parser(str(file_path), parser_class)
        if result_parser is None:
            raise ValueError(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ —Ñ–∞–π–ª–∞ {filename}")
        
        if len(result_parser.text) == 0:
            raise ValueError(f"–§–∞–π–ª {filename} –ø—É—Å—Ç–æ–π")
        
        text_length = len(result_parser.text)
        logger.info(f"[{worker_name}] –ü–∞—Ä—Å–∏–Ω–≥ –∑–∞–≤–µ—Ä—à–µ–Ω: {text_length} —Å–∏–º–≤–æ–ª–æ–≤")

        # 5. –†–∞–∑–±–∏–µ–Ω–∏–µ –Ω–∞ —á–∞–Ω–∫–∏ (—à–∞–≥ 4)
        if task_id and not task_id.startswith('celery-'):
            update_task_status_sync(
                task_id,
                current_step=5,
                progress=60,
                status="processing",
                message="–†–∞–∑–±–∏–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –Ω–∞ —Å–º—ã—Å–ª–æ–≤—ã–µ —á–∞–Ω–∫–∏..."
            )
        
        chunks = splitter.split_text(result_parser.text)
        chunks_count = len(chunks)
        
        if chunks_count == 0:
            raise ValueError("–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å —á–∞–Ω–∫–∏ –∏–∑ —Ç–µ–∫—Å—Ç–∞")
        
        logger.info(f"[{worker_name}] –°–æ–∑–¥–∞–Ω–æ —á–∞–Ω–∫–æ–≤: {chunks_count}")

        # 6. –°–æ–∑–¥–∞–Ω–∏–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö (—à–∞–≥ 5)
        if task_id and not task_id.startswith('celery-'):
            update_task_status_sync(
                task_id,
                current_step=6,
                progress=75,
                status="processing",
                message="–§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–∞..."
            )
        
        logger.info(f"[{worker_name}] –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ —Å–æ–∑–¥–∞–Ω—ã")
        
        # 7. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ –≤–µ–∫—Ç–æ—Ä–Ω—É—é –ë–î (—à–∞–≥ 6) - –ó–ê–ö–û–ú–ú–ï–ù–¢–ò–†–û–í–ê–ù–û
        # if task_id and not task_id.startswith('celery-'):
        #     update_task_status_sync(
        #         task_id,
        #         progress=90,
        #         status="processing",
        #         message="–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ –≤–µ–∫—Ç–æ—Ä–Ω—É—é –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö..."
        #     )
        
        # –û—á–∏—Å—Ç–∫–∞ —Ñ–∞–π–ª–∞
        _cleanup_file(filename, worker_name)
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        result = {
            "status": "success",
            "filename": filename,
            "display_name": dispach or filenames.name,
            "worker": worker_name,
            "text_length": text_length,
            "chunks_count": chunks_count,
            "file_extension": ext,
            "processed_at": datetime.now().isoformat()
        }
        
        # 8. –§–∏–Ω–∞–ª—å–Ω–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç—É—Å–∞
        if task_id and not task_id.startswith('celery-'):
            update_task_status_sync(
                task_id,
                status="completed",
                progress=100,
                current_step=6,
                total_steps=6,
                message="–û–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–∞–π–ª–∞ —É—Å–ø–µ—à–Ω–æ –∑–∞–≤–µ—Ä—à–µ–Ω–∞!",
                result=result,
                completed_at=datetime.now().isoformat()
            )
        
        logger.info(f"‚úÖ [{worker_name}] –§–∞–π–ª {filename} —É—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω!")
        
        return result
        
    except FileNotFoundError as e:
        error_msg = str(e)
        logger.error(f"[{worker_name}] –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {error_msg}")
        
        if task_id and not task_id.startswith('celery-'):
            update_task_status_sync(
                task_id,
                status="failed",
                progress=100,
                message=f"–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {error_msg}",
                error={
                    "type": "file_not_found",
                    "message": error_msg
                },
                completed_at=datetime.now().isoformat()
            )
        
        raise
        
    except ValueError as e:
        error_msg = str(e)
        logger.error(f"[{worker_name}] –û—à–∏–±–∫–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏: {error_msg}")
        
        if task_id and not task_id.startswith('celery-'):
            update_task_status_sync(
                task_id,
                status="failed",
                progress=100,
                message=f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏: {error_msg}",
                error={
                    "type": "validation_error",
                    "message": error_msg
                },
                completed_at=datetime.now().isoformat()
            )
        
        raise
        
    except Exception as e:
        error_msg = f"–ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è –æ—à–∏–±–∫–∞: {str(e)}"
        logger.error(f"[{worker_name}] {error_msg}")
        
        # –û—á–∏—Å—Ç–∫–∞ —Ñ–∞–π–ª–∞ –≤ —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏
        _cleanup_file(filename, worker_name)
        
        if task_id and not task_id.startswith('celery-'):
            update_task_status_sync(
                task_id,
                status="failed",
                progress=100,
                message=f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {error_msg}",
                error={
                    "type": "unexpected_error",
                    "message": error_msg,
                    "exception_type": type(e).__name__
                },
                completed_at=datetime.now().isoformat()
            )
        
        raise

@celery_app.task(bind=True, name='app.tasks.processing.generate_embedding_batch')
def generate_embedding_batch(self, file_paths: list[str], folder_name: str = "", api_task_id: str = None):
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö —Ñ–∞–π–ª–æ–≤ –∏–∑ –ø–∞–ø–∫–∏ —Å –æ–±—â–∏–º –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å–∞"""
    
    worker_name = self.request.hostname
    task_id = api_task_id or self.request.id
    total_files = len(file_paths)
    processed_files = 0
    results = []
    errors = []
    
    logger.info(f"üöÄ [{worker_name}] Starting batch task {task_id}: {total_files} files in {folder_name}")
    
    # –ù–∞—á–∞–ª—å–Ω—ã–π —Å—Ç–∞—Ç—É—Å –¥–ª—è batch –∑–∞–¥–∞—á–∏
    if task_id and not task_id.startswith('celery-'):
        update_task_status_sync(
            task_id,
            status="processing",
            progress=0,
            message=f"–ù–∞—á–∏–Ω–∞–µ—Ç—Å—è –ø–∞–∫–µ—Ç–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞: {total_files} —Ñ–∞–π–ª–æ–≤",
            folder_name=folder_name,
            total_files=total_files,
            started_at=datetime.now().isoformat()
        )
    
    try:
        for idx, file_path_str in enumerate(file_paths, 1):
            file_path = Path(file_path_str)
            filename = file_path.name
            
            try:
                progress = int((idx - 1) / total_files * 100)
                
                # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç—É—Å –ø—Ä–æ–≥—Ä–µ—Å—Å–∞
                if task_id and not task_id.startswith('celery-'):
                    update_task_status_sync(
                        task_id,
                        progress=progress,
                        current_file=idx,
                        processed=processed_files,
                        errors=len(errors),
                        message=f'–û–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–∞–π–ª–∞ {idx}/{total_files}: {filename}'
                    )
                
                logger.info(f"[{worker_name}] [{idx}/{total_files}] –û–±—Ä–∞–±–æ—Ç–∫–∞: {filename}")
                
                # –ó–∞–ø—É—Å–∫–∞–µ–º –∑–∞–¥–∞—á—É –¥–ª—è –æ—Ç–¥–µ–ª—å–Ω–æ–≥–æ —Ñ–∞–π–ª–∞
                async_result = generate_embedding.apply_async(
                    args=[str(file_path_str)],
                    kwargs={"onlyfile": True, "api_task_id": f"{task_id}_{idx}"},
                    queue="documents.tasks"
                )
                
                # –ñ–¥–µ–º –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –∑–∞–¥–∞—á–∏
                task_result = async_result.get(timeout=300)  # 5 –º–∏–Ω—É—Ç —Ç–∞–π–º–∞—É—Ç
                
                if task_result.get('status') == 'skipped':
                    results.append({
                        'filename': filename,
                        'file_path': file_path_str,
                        'status': 'skipped',
                        'reason': task_result.get('reason')
                    })
                    logger.info(f"[{worker_name}] [{idx}/{total_files}] –ü—Ä–æ–ø—É—â–µ–Ω: {filename}")
                else:
                    processed_files += 1
                    results.append({
                        'filename': filename,
                        'file_path': file_path_str,
                        'status': 'success',
                        'result': task_result
                    })
                    logger.info(f"[{worker_name}] [{idx}/{total_files}] –£—Å–ø–µ—à–Ω–æ: {filename}")
                    
            except Exception as e:
                error_msg = f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ {filename}: {str(e)}"
                logger.error(f"[{worker_name}] {error_msg}")
                errors.append({
                    'filename': filename,
                    'file_path': file_path_str,
                    'error': error_msg
                })
        
        # –§–∏–Ω–∞–ª—å–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç batch –æ–±—Ä–∞–±–æ—Ç–∫–∏
        final_result = {
            "status": "completed",
            "folder_name": folder_name,
            "worker": worker_name,
            "total_files": total_files,
            "processed": processed_files,
            "errors_count": len(errors),
            "results": results,
            "errors": errors,
            "completed_at": datetime.now().isoformat()
        }
        
        logger.info(f"‚úÖ [{worker_name}] –ü–∞–∫–µ—Ç–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞: {processed_files}/{total_files} —É—Å–ø–µ—à–Ω–æ")

        # –û—á–∏—Å—Ç–∫–∞ –ø–∞–ø–∫–∏ –µ—Å–ª–∏ –æ–Ω–∞ –±—ã–ª–∞ –∑–∞–≥—Ä—É–∂–µ–Ω–∞
        if folder_name:
            uploads_dir = Path("uploads")
            folder_path = uploads_dir / folder_name

            if folder_path.exists() and folder_path.is_dir():
                shutil.rmtree(folder_path)
                logger.info(f"[{worker_name}] –ü–∞–ø–∫–∞ {folder_path} —É–¥–∞–ª–µ–Ω–∞")

        # –§–∏–Ω–∞–ª—å–Ω–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç—É—Å–∞
        if task_id and not task_id.startswith('celery-'):
            update_task_status_sync(
                task_id,
                status="completed",
                progress=100,
                message=f"–ü–∞–∫–µ—Ç–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞: {processed_files}/{total_files} —É—Å–ø–µ—à–Ω–æ",
                result=final_result,
                completed_at=datetime.now().isoformat()
            )

        return final_result
        
    except Exception as e:
        error_msg = f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –ø–∞–∫–µ—Ç–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏: {str(e)}"
        logger.error(f"[{worker_name}] {error_msg}")
        
        if task_id and not task_id.startswith('celery-'):
            update_task_status_sync(
                task_id,
                status="failed",
                progress=100,
                message=error_msg,
                error={
                    "type": "batch_processing_error",
                    "message": error_msg
                },
                completed_at=datetime.now().isoformat()
            )
        
        raise